{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T04:27:42.508616Z",
     "start_time": "2025-06-24T04:24:44.090136Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "\n",
    "# ------------------------------\n",
    "# DEBUGGING & CONFIGURATION\n",
    "# ------------------------------\n",
    "# This forces CUDA operations to be synchronous for accurate error reporting.\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"model_name\": \"ViT-B-16\",\n",
    "    \"pretrained\": \"laion2b_s34b_b88k\",\n",
    "    \"csv_train\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/train.csv\",\n",
    "    \"csv_val\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/valid.csv\",\n",
    "    \"csv_test\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/test.csv\",\n",
    "    \"save_path\": \"finetuned_expression_only_best.pt\", # <-- New save path\n",
    "    \"plot_save_dir\": \"test_results_expression_only\", # <-- New plot directory\n",
    "    \"num_plots\": 100,\n",
    "    \"batch_size\": 32, # Start small for large models\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-6,\n",
    "    \"patience\": 10,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "    # --- FOCUSED: Prompts for Expression ONLY ---\n",
    "    \"expression_prompts\": [\n",
    "        \"a photo of a person with an anger expression.\", \"a photo of a person with a contempt expression.\",\n",
    "        \"a photo of a person with a disgust expression.\", \"a photo of a person with a happiness expression.\",\n",
    "        \"a photo of a person with a fear expression.\", \"a photo of a person with a sadness expression.\",\n",
    "        \"a photo of a person with a surprise expression.\", \"a photo of a person with a neutral expression.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Create simplified keys from prompts for mapping ---\n",
    "CONFIG[\"expression_keys\"] = [p.split(\" with \")[-1].replace(\"an \", \"\").replace(\"a \", \"\").replace(\" expression.\", \"\") for p in CONFIG[\"expression_prompts\"]]\n",
    "print(CONFIG[\"expression_keys\"])\n",
    "# ------------------------------\n",
    "# Helper Function for Parsing\n",
    "# ------------------------------\n",
    "def parse_expression_from_prompt(prompt_text):\n",
    "    \"\"\"\n",
    "    A robust parser to find any of the expression keys in the prompt.\n",
    "    \"\"\"\n",
    "    # Search for any of the expression keys from the list in the prompt text\n",
    "    for expression_key in CONFIG[\"expression_keys\"]:\n",
    "        # Use regex with word boundaries (\\b) to ensure it matches the whole word/phrase\n",
    "        if re.search(r'\\b' + re.escape(expression_key) + r'\\b', prompt_text, re.IGNORECASE):\n",
    "            return expression_key\n",
    "    return None\n",
    "\n",
    "# ------------------------------\n",
    "# Preprocessing and Caching\n",
    "# ------------------------------\n",
    "def preprocess_and_cache_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Parses prompts for expression and saves a cached version.\n",
    "    \"\"\"\n",
    "    cache_path = csv_path.replace(\".csv\", \".expression_cached.csv\")\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading preprocessed expression data from cache: {cache_path}\")\n",
    "        try:\n",
    "            df_cache = pd.read_csv(cache_path)\n",
    "            if df_cache.empty:\n",
    "                 print(\"Warning: Cached file is empty. Reprocessing.\")\n",
    "            else:\n",
    "                return df_cache\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: Cached file is empty. Reprocessing.\")\n",
    "\n",
    "    print(f\"Preprocessing expression data and caching: {csv_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print(f\"Error or empty file at {csv_path}\")\n",
    "        return None\n",
    "\n",
    "    new_data = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preprocessing {os.path.basename(csv_path)}\"):\n",
    "        expression = parse_expression_from_prompt(row['prompt'])\n",
    "        if expression:\n",
    "            row_data = {\n",
    "                'filepath': row['filepath'],\n",
    "                'prompt': row['prompt'],\n",
    "                'expression_idx': CONFIG[\"expression_keys\"].index(expression)\n",
    "            }\n",
    "            new_data.append(row_data)\n",
    "\n",
    "    if not new_data:\n",
    "        print(\"Warning: Preprocessing resulted in an empty dataset for expression.\")\n",
    "        return None\n",
    "\n",
    "    cached_df = pd.DataFrame(new_data)\n",
    "    cached_df.to_csv(cache_path, index=False)\n",
    "    return cached_df\n",
    "\n",
    "# ------------------------------\n",
    "# Dataset Class\n",
    "# ------------------------------\n",
    "class ExpressionDataset(Dataset):\n",
    "    def __init__(self, df, preprocess):\n",
    "        self.df = df if df is not None else pd.DataFrame()\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row[\"filepath\"]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = self.preprocess(image)\n",
    "        except FileNotFoundError:\n",
    "            image = torch.zeros((3, 224, 224))\n",
    "\n",
    "        expression_idx = torch.tensor(row[\"expression_idx\"])\n",
    "        return image, expression_idx, image_path\n",
    "\n",
    "# ------------------------------\n",
    "# Training and Evaluation Functions\n",
    "# ------------------------------\n",
    "def train_and_validate(model, train_loader, val_loader, expression_text_features):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    model_saved = False\n",
    "\n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for images, gt_indices, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Train]\"):\n",
    "            images, gt_indices = images.to(CONFIG[\"device\"]), gt_indices.to(CONFIG[\"device\"])\n",
    "\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            logits_per_image = (100.0 * image_features @ expression_text_features.T)\n",
    "            loss = loss_fn(logits_per_image, gt_indices)\n",
    "\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, gt_indices, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Val]\"):\n",
    "                images, gt_indices = images.to(CONFIG[\"device\"]), gt_indices.to(CONFIG[\"device\"])\n",
    "                image_features = model.encode_image(images)\n",
    "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "                logits_per_image = (100.0 * image_features @ expression_text_features.T)\n",
    "                loss = loss_fn(logits_per_image, gt_indices)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"âœ… Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), CONFIG[\"save_path\"])\n",
    "            print(f\"ðŸŽ‰ Saved best model to {CONFIG['save_path']}\")\n",
    "            patience_counter = 0\n",
    "            model_saved = True\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"âš ï¸ No improvement. Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        if patience_counter >= CONFIG[\"patience\"]:\n",
    "            print(\"ðŸ›‘ Early stopping triggered.\"); break\n",
    "\n",
    "    return model_saved\n",
    "\n",
    "\n",
    "def test_and_plot(model, expression_text_features, preprocess):\n",
    "    print(\"\\n--- Starting Final Testing and Plotting Phase for Expression ---\")\n",
    "    model.load_state_dict(torch.load(CONFIG[\"save_path\"])); model.to(CONFIG[\"device\"]).eval()\n",
    "    print(\"Best model loaded.\")\n",
    "\n",
    "    test_df = preprocess_and_cache_csv(CONFIG[\"csv_test\"])\n",
    "    if test_df is None or test_df.empty:\n",
    "        print(f\"Error or empty data in test CSV. Halting testing.\")\n",
    "        return\n",
    "\n",
    "    test_dataset = ExpressionDataset(test_df, preprocess)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    correct_predictions, total_samples = 0, 0\n",
    "    all_results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, gt_indices, image_paths in tqdm(test_loader, desc=\"[Testing Expression]\"):\n",
    "            images = images.to(CONFIG[\"device\"])\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            logits = (100.0 * image_features @ expression_text_features.T)\n",
    "            preds = logits.argmax(dim=-1)\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                is_correct = (preds[i] == gt_indices[i]).item()\n",
    "                if is_correct: correct_predictions += 1\n",
    "\n",
    "                all_results.append({\n",
    "                    \"image_path\": image_paths[i],\n",
    "                    \"ground_truth\": CONFIG[\"expression_keys\"][gt_indices[i]],\n",
    "                    \"prediction\": CONFIG[\"expression_keys\"][preds[i]],\n",
    "                    \"is_correct\": is_correct\n",
    "                })\n",
    "            total_samples += len(images)\n",
    "\n",
    "    if total_samples > 0:\n",
    "        accuracy = (correct_predictions / total_samples) * 100\n",
    "        print(f\"\\nðŸ“Š Expression Test Accuracy: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(\"No valid samples were processed in the test set.\")\n",
    "\n",
    "    print(f\"\\n--- Plotting up to {CONFIG['num_plots']} expression results ---\")\n",
    "    os.makedirs(CONFIG[\"plot_save_dir\"], exist_ok=True)\n",
    "\n",
    "    for i, result in enumerate(all_results):\n",
    "        if i >= CONFIG[\"num_plots\"]: break\n",
    "        try:\n",
    "            img = Image.open(result[\"image_path\"])\n",
    "        except FileNotFoundError: continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 10))\n",
    "        ax.imshow(img); ax.axis(\"off\")\n",
    "\n",
    "        title = f\"Result {i+1}: {'CORRECT' if result['is_correct'] else 'INCORRECT'}\"\n",
    "        color = 'green' if result['is_correct'] else 'red'\n",
    "        fig.suptitle(title, fontsize=16, color=color)\n",
    "\n",
    "        text = (f\"Ground Truth: {result['ground_truth']}\\n\"\n",
    "                f\"Prediction:   {result['prediction']}\")\n",
    "\n",
    "        ax.set_title(text, fontsize=12, pad=10)\n",
    "\n",
    "        save_name = f\"result_{i+1}_{'correct' if result['is_correct'] else 'incorrect'}.png\"\n",
    "        plt.savefig(os.path.join(CONFIG[\"plot_save_dir\"], save_name), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"--- Plotting complete ---\")\n",
    "\n",
    "# ==============================\n",
    "#      MAIN EXECUTION BLOCK\n",
    "# ==============================\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Using device: {CONFIG['device']}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch Version: {torch.__version__}, CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "        CONFIG[\"model_name\"], pretrained=CONFIG[\"pretrained\"], device=CONFIG[\"device\"]\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(CONFIG[\"model_name\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        expression_text_tokens = tokenizer(CONFIG[\"expression_prompts\"]).to(CONFIG[\"device\"])\n",
    "        expression_text_features = model.encode_text(expression_text_tokens)\n",
    "        expression_text_features = expression_text_features / expression_text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    train_df = preprocess_and_cache_csv(CONFIG[\"csv_train\"])\n",
    "    val_df = preprocess_and_cache_csv(CONFIG[\"csv_val\"])\n",
    "\n",
    "    if train_df is not None and val_df is not None and not train_df.empty and not val_df.empty:\n",
    "        train_dataset = ExpressionDataset(train_df, preprocess)\n",
    "        val_dataset = ExpressionDataset(val_df, preprocess)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "        training_successful = train_and_validate(model, train_loader, val_loader, expression_text_features)\n",
    "\n",
    "        if training_successful:\n",
    "            test_and_plot(model, expression_text_features, preprocess)\n",
    "        else:\n",
    "            print(\"\\nSkipping testing phase: No model was saved during training.\")\n",
    "    else:\n",
    "        print(\"\\nSkipping training: Training/validation datasets are empty or could not be loaded.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'contempt', 'disgust', 'happiness', 'fear', 'sadness', 'surprise', 'neutral']\n",
      "Using device: cuda\n",
      "PyTorch Version: 2.8.0.dev20250507+cu128, CUDA Version: 12.8\n",
      "Loading preprocessed expression data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/train.expression_cached.csv\n",
      "Loading preprocessed expression data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/valid.expression_cached.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Epoch 1/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1: Train Loss = 1.4295, Val Loss = 1.1663\n",
      "ðŸŽ‰ Saved best model to finetuned_expression_only_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Epoch 2/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2: Train Loss = 0.9854, Val Loss = 1.0611\n",
      "ðŸŽ‰ Saved best model to finetuned_expression_only_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Epoch 3/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3: Train Loss = 0.8577, Val Loss = 1.0232\n",
      "ðŸŽ‰ Saved best model to finetuned_expression_only_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Epoch 4/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4: Train Loss = 0.7617, Val Loss = 1.0309\n",
      "âš ï¸ No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.06it/s]\n",
      "Epoch 5/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5: Train Loss = 0.6756, Val Loss = 1.0771\n",
      "âš ï¸ No improvement. Patience: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.07it/s]\n",
      "Epoch 6/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6: Train Loss = 0.5772, Val Loss = 1.0926\n",
      "âš ï¸ No improvement. Patience: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.05it/s]\n",
      "Epoch 7/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7: Train Loss = 0.4924, Val Loss = 1.1450\n",
      "âš ï¸ No improvement. Patience: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.05it/s]\n",
      "Epoch 8/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8: Train Loss = 0.4075, Val Loss = 1.1853\n",
      "âš ï¸ No improvement. Patience: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.03it/s]\n",
      "Epoch 9/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9: Train Loss = 0.3336, Val Loss = 1.2399\n",
      "âš ï¸ No improvement. Patience: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.04it/s]\n",
      "Epoch 10/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10: Train Loss = 0.2613, Val Loss = 1.2721\n",
      "âš ï¸ No improvement. Patience: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.02it/s]\n",
      "Epoch 11/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 11: Train Loss = 0.2056, Val Loss = 1.3860\n",
      "âš ï¸ No improvement. Patience: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.02it/s]\n",
      "Epoch 12/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 12: Train Loss = 0.1584, Val Loss = 1.4373\n",
      "âš ï¸ No improvement. Patience: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.02it/s]\n",
      "Epoch 13/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 13: Train Loss = 0.1170, Val Loss = 1.5098\n",
      "âš ï¸ No improvement. Patience: 10/10\n",
      "ðŸ›‘ Early stopping triggered.\n",
      "\n",
      "--- Starting Final Testing and Plotting Phase for Expression ---\n",
      "Best model loaded.\n",
      "Loading preprocessed expression data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/test.expression_cached.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing Expression]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Expression Test Accuracy: 59.00%\n",
      "\n",
      "--- Plotting up to 100 expression results ---\n",
      "--- Plotting complete ---\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf964145eb8803ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

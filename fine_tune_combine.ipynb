{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T10:29:38.777416Z",
     "start_time": "2025-06-30T10:26:09.340061Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import re\n",
    "\n",
    "# ------------------------------\n",
    "# DEBUGGING & CONFIGURATION\n",
    "# ------------------------------\n",
    "# This forces CUDA operations to be synchronous for accurate error reporting.\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"model_name\": \"ViT-B-16\",\n",
    "    \"pretrained\": \"datacomp_xl_s13b_b90k\",\n",
    "    \"csv_train\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/train.csv\",\n",
    "    \"csv_val\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/valid.csv\",\n",
    "    \"csv_test\": \"C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/test.csv\",\n",
    "    \"save_path\": \"finetuned_multi_attribute_final_consistent.pt\",\n",
    "    \"plot_save_dir\": \"test_results_multi_attribute_final\",\n",
    "    \"num_plots\": 100,\n",
    "    \"batch_size\": 8, # Start small for large models to avoid CUDA OOM errors\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-6,\n",
    "    \"patience\": 5,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "    \"identity_prompts\": [\n",
    "        \"A photo of soekarno.\", \"A photo of suharto.\", \"A photo of baharuddin jusuf habibie.\",\n",
    "        \"A photo of abdurrahman wahid.\", \"A photo of megawati sukarnoputri.\",\n",
    "        \"A photo of susilo bambang yudhoyono.\", \"A photo of joko widodo.\",\n",
    "        \"A photo of prabowo subianto.\", \"A photo of anies rasyid baswedan.\",\n",
    "        \"A photo of ganjar pranowo.\", \"A photo of gibran rakabuming raka.\",\n",
    "        \"A photo of maruf amin.\", \"A photo of airlangga hartarto.\",\n",
    "        \"A photo of sri mulyani indrawati.\", \"A photo of erick thohir.\",\n",
    "        \"A photo of agus harimurti yudhoyono.\", \"A photo of muhaimin iskandar.\",\n",
    "        \"A photo of mahfud md.\", \"A photo of boediono\", \"A photo of jusuf kalla\"\n",
    "    ],\n",
    "    \"age_prompts\": [\"a photo of a teenager.\", \"a photo of a young adult.\", \"a photo of a middle-aged person.\", \"a photo of a late adult.\", \"a photo of an elderly person.\"],\n",
    "    \"gender_prompts\": [\"a photo of a male person.\", \"a photo of a female person.\"],\n",
    "    \"expression_prompts\": [\n",
    "        \"a photo of a person with an anger expression.\", \"a photo of a person with a contempt expression.\",\n",
    "        \"a photo of a person with a disgust expression.\", \"a photo of a person with a happiness expression.\",\n",
    "        \"a photo of a person with a fear expression.\", \"a photo of a person with a sadness expression.\",\n",
    "        \"a photo of a person with a surprise expression.\", \"a photo of a person with a neutral expression.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Create simplified keys from prompts for mapping ---\n",
    "CONFIG[\"identity_keys\"] = [p.replace(\"A photo of \", \"\").replace(\".\", \"\") for p in CONFIG[\"identity_prompts\"]]\n",
    "CONFIG[\"age_keys\"] = [p.replace(\"a photo of \", \"\").replace(\"a \", \"\").replace(\"an \", \"\").replace(\" person\", \"\").replace(\".\", \"\") for p in CONFIG[\"age_prompts\"]]\n",
    "CONFIG[\"gender_keys\"] = [\"male\", \"female\"]\n",
    "CONFIG[\"expression_keys\"] = [p.split(\" with \")[-1].replace(\"a \", \"\").replace(\"an \", \"\").replace(\" expression.\", \"\") for p in CONFIG[\"expression_prompts\"]]\n",
    "# print(CONFIG[\"identity_keys\"], CONFIG[\"age_keys\"], CONFIG[\"gender_keys\"], CONFIG[\"expression_keys\"])\n",
    "# ------------------------------\n",
    "# Helper Functions\n",
    "# ------------------------------\n",
    "def parse_training_prompt(prompt_text):\n",
    "    \"\"\"Parses a consistent prompt template to extract all attributes.\"\"\"\n",
    "    # This regex is specifically for the format: \"Name, gender, age_group, expression.\"\n",
    "    pattern = r\"^(.*?),\\s*(male|female),\\s*(.*?),\\s*(.*?)\\.$\"\n",
    "    match = re.search(pattern, prompt_text.strip(), re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        attrs = {\n",
    "            \"name\": match.group(1).strip().lower(),\n",
    "            \"gender\": match.group(2).strip().lower(),\n",
    "            \"age_group\": match.group(3).strip().lower(),\n",
    "            \"expression\": match.group(4).strip().lower()\n",
    "        }\n",
    "        return attrs\n",
    "    return None\n",
    "\n",
    "def preprocess_and_cache_csv(csv_path):\n",
    "    \"\"\"Parses all attributes and saves a single cached version.\"\"\"\n",
    "    cache_path = csv_path.replace(\".csv\", \".multi_attribute_cached.csv\")\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading preprocessed data from cache: {cache_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(cache_path)\n",
    "            if df.empty:\n",
    "                 print(\"Warning: Cached file is empty. Reprocessing.\")\n",
    "            else:\n",
    "                return df\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: Cached file is empty. Reprocessing.\")\n",
    "\n",
    "    print(f\"Preprocessing and caching data from: {csv_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if df.empty:\n",
    "            print(f\"Warning: Original CSV file is empty: {csv_path}\")\n",
    "            return None\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print(f\"Error or empty file at {csv_path}\")\n",
    "        return None\n",
    "\n",
    "    new_data = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preprocessing {os.path.basename(csv_path)}\"):\n",
    "        attrs = parse_training_prompt(row['prompt'])\n",
    "        if attrs:\n",
    "            row_data = {\n",
    "                'filepath': row['filepath'],\n",
    "                'prompt': row['prompt'],\n",
    "                'identity_idx': CONFIG[\"identity_keys\"].index(attrs[\"name\"]) if attrs.get(\"name\") in CONFIG[\"identity_keys\"] else -1,\n",
    "                'gender_idx': CONFIG[\"gender_keys\"].index(attrs[\"gender\"]) if attrs.get(\"gender\") in CONFIG[\"gender_keys\"] else -1,\n",
    "                'age_idx': CONFIG[\"age_keys\"].index(attrs[\"age_group\"]) if attrs.get(\"age_group\") in CONFIG[\"age_keys\"] else -1,\n",
    "                'expression_idx': CONFIG[\"expression_keys\"].index(attrs[\"expression\"]) if attrs.get(\"expression\") in CONFIG[\"expression_keys\"] else -1\n",
    "            }\n",
    "            new_data.append(row_data)\n",
    "\n",
    "    if not new_data:\n",
    "        print(\"Warning: Preprocessing resulted in an empty dataset. Check prompt templates and keys.\")\n",
    "        return None\n",
    "\n",
    "    cached_df = pd.DataFrame(new_data)\n",
    "    cached_df.to_csv(cache_path, index=False)\n",
    "    return cached_df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Dataset Class\n",
    "# ------------------------------\n",
    "class MultiAttributeDataset(Dataset):\n",
    "    def __init__(self, df, preprocess):\n",
    "        self.df = df if df is not None else pd.DataFrame()\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row[\"filepath\"]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = self.preprocess(image)\n",
    "        except FileNotFoundError:\n",
    "            image = torch.zeros((3, 224, 224))\n",
    "\n",
    "        gt_indices = torch.tensor([\n",
    "            row[\"identity_idx\"], row[\"gender_idx\"],\n",
    "            row[\"age_idx\"], row[\"expression_idx\"]\n",
    "        ])\n",
    "\n",
    "        return image, gt_indices, image_path\n",
    "\n",
    "# ------------------------------\n",
    "# Main Training & Testing Functions\n",
    "# ------------------------------\n",
    "def train_and_validate(model, train_loader, val_loader, all_text_features):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "    # --- ADDED: ignore_index=-1 tells the loss function to skip samples that couldn't be parsed.\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    model_saved = False\n",
    "\n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        model.train()\n",
    "        total_loss_sum = 0\n",
    "        for images, gt_indices, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Train]\"):\n",
    "            images, gt_indices = images.to(CONFIG[\"device\"]), gt_indices.to(CONFIG[\"device\"])\n",
    "\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            logits = (100.0 * image_features @ all_text_features.T)\n",
    "\n",
    "            offset = 0\n",
    "            identity_logits = logits[:, offset:offset+len(CONFIG[\"identity_prompts\"])]; offset += len(CONFIG[\"identity_prompts\"])\n",
    "            gender_logits = logits[:, offset:offset+len(CONFIG[\"gender_prompts\"])]; offset += len(CONFIG[\"gender_prompts\"])\n",
    "            age_logits = logits[:, offset:offset+len(CONFIG[\"age_prompts\"])]; offset += len(CONFIG[\"age_prompts\"])\n",
    "            expression_logits = logits[:, offset:offset+len(CONFIG[\"expression_prompts\"])]\n",
    "\n",
    "            loss_identity = loss_fn(identity_logits, gt_indices[:, 0])\n",
    "            loss_gender = loss_fn(gender_logits, gt_indices[:, 1])\n",
    "            loss_age = loss_fn(age_logits, gt_indices[:, 2])\n",
    "            loss_expression = loss_fn(expression_logits, gt_indices[:, 3])\n",
    "\n",
    "            total_loss = loss_identity + loss_gender + loss_age + loss_expression\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "\n",
    "            # --- ADDED: Gradient Clipping to prevent exploding gradients and NaN loss ---\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss_sum += total_loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss_sum / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss_sum = 0\n",
    "        with torch.no_grad():\n",
    "            for images, gt_indices, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Val]\"):\n",
    "                images, gt_indices = images.to(CONFIG[\"device\"]), gt_indices.to(CONFIG[\"device\"])\n",
    "                image_features = model.encode_image(images)\n",
    "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "                logits = (100.0 * image_features @ all_text_features.T)\n",
    "\n",
    "                offset = 0\n",
    "                identity_logits = logits[:, offset:offset+len(CONFIG[\"identity_prompts\"])]; offset += len(CONFIG[\"identity_prompts\"])\n",
    "                gender_logits = logits[:, offset:offset+len(CONFIG[\"gender_prompts\"])]; offset += len(CONFIG[\"gender_prompts\"])\n",
    "                age_logits = logits[:, offset:offset+len(CONFIG[\"age_prompts\"])]; offset += len(CONFIG[\"age_prompts\"])\n",
    "                expression_logits = logits[:, offset:offset+len(CONFIG[\"expression_prompts\"])]\n",
    "\n",
    "                loss_identity = loss_fn(identity_logits, gt_indices[:, 0])\n",
    "                loss_gender = loss_fn(gender_logits, gt_indices[:, 1])\n",
    "                loss_age = loss_fn(age_logits, gt_indices[:, 2])\n",
    "                loss_expression = loss_fn(expression_logits, gt_indices[:, 3])\n",
    "                total_loss = loss_identity + loss_gender + loss_age + loss_expression\n",
    "                total_val_loss_sum += total_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss_sum / len(val_loader)\n",
    "        print(f\"âœ… Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), CONFIG[\"save_path\"])\n",
    "            print(f\"ðŸŽ‰ Saved best model to {CONFIG['save_path']}\")\n",
    "            patience_counter = 0\n",
    "            model_saved = True\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"âš ï¸ No improvement. Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        if patience_counter >= CONFIG[\"patience\"]:\n",
    "            print(\"ðŸ›‘ Early stopping triggered.\"); break\n",
    "\n",
    "    return model_saved\n",
    "\n",
    "def test_and_plot(model, all_text_features, preprocess):\n",
    "    print(\"\\n--- Starting Final Testing and Plotting Phase ---\")\n",
    "    model.load_state_dict(torch.load(CONFIG[\"save_path\"])); model.to(CONFIG[\"device\"]).eval()\n",
    "    print(\"Best model loaded.\")\n",
    "\n",
    "    test_df = preprocess_and_cache_csv(CONFIG[\"csv_test\"])\n",
    "    if test_df is None or test_df.empty:\n",
    "        print(f\"Error or empty data in test CSV. Halting testing.\")\n",
    "        return\n",
    "\n",
    "    test_dataset = MultiAttributeDataset(test_df, preprocess)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    attribute_correct, total_samples = 0, 0\n",
    "    all_results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, gt_indices, image_paths in tqdm(test_loader, desc=\"[Testing]\"):\n",
    "            images = images.to(CONFIG[\"device\"])\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            logits = (100.0 * image_features @ all_text_features.T)\n",
    "            offset = 0\n",
    "            identity_logits = logits[:, offset:offset+len(CONFIG[\"identity_prompts\"])]; offset += len(CONFIG[\"identity_prompts\"])\n",
    "            gender_logits = logits[:, offset:offset+len(CONFIG[\"gender_prompts\"])]; offset += len(CONFIG[\"gender_prompts\"])\n",
    "            age_logits = logits[:, offset:offset+len(CONFIG[\"age_prompts\"])]; offset += len(CONFIG[\"age_prompts\"])\n",
    "            expression_logits = logits[:, offset:offset+len(CONFIG[\"expression_prompts\"])]\n",
    "\n",
    "            pred_identity_indices = identity_logits.argmax(dim=-1)\n",
    "            pred_gender_indices = gender_logits.argmax(dim=-1)\n",
    "            pred_age_indices = age_logits.argmax(dim=-1)\n",
    "            pred_expression_indices = expression_logits.argmax(dim=-1)\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                gt_attrs = {\n",
    "                    \"name\": CONFIG[\"identity_keys\"][gt_indices[i, 0]],\n",
    "                    \"gender\": CONFIG[\"gender_keys\"][gt_indices[i, 1]],\n",
    "                    \"age_group\": CONFIG[\"age_keys\"][gt_indices[i, 2]],\n",
    "                    \"expression\": CONFIG[\"expression_keys\"][gt_indices[i, 3]],\n",
    "                }\n",
    "\n",
    "                pred_attrs = {\n",
    "                    \"name\": CONFIG[\"identity_keys\"][pred_identity_indices[i]],\n",
    "                    \"gender\": CONFIG[\"gender_keys\"][pred_gender_indices[i]],\n",
    "                    \"age_group\": CONFIG[\"age_keys\"][pred_age_indices[i]],\n",
    "                    \"expression\": CONFIG[\"expression_keys\"][pred_expression_indices[i]],\n",
    "                }\n",
    "\n",
    "                is_correct = (gt_attrs[\"name\"] == pred_attrs[\"name\"] and\n",
    "                              gt_attrs[\"age_group\"] == pred_attrs[\"age_group\"] and\n",
    "                              gt_attrs[\"expression\"] == pred_attrs[\"expression\"])\n",
    "\n",
    "                if is_correct: attribute_correct += 1\n",
    "\n",
    "                all_results.append({\n",
    "                    \"image_path\": image_paths[i], \"gt_attrs\": gt_attrs,\n",
    "                    \"pred_attrs\": pred_attrs, \"is_correct\": is_correct\n",
    "                })\n",
    "                total_samples += 1\n",
    "\n",
    "    if total_samples > 0:\n",
    "        attr_accuracy = (attribute_correct / total_samples) * 100\n",
    "        print(\"\\n--- Test Results ---\")\n",
    "        print(f\"ðŸ“Š Attribute Accuracy: {attr_accuracy:.2f}% (Correct if Name, Age, and Expression all match)\")\n",
    "    else:\n",
    "        print(\"No valid samples were processed in the test set.\")\n",
    "\n",
    "    print(f\"\\n--- Plotting up to {CONFIG['num_plots']} results ---\")\n",
    "    os.makedirs(CONFIG[\"plot_save_dir\"], exist_ok=True)\n",
    "\n",
    "    for i, result in enumerate(all_results):\n",
    "        if i >= CONFIG[\"num_plots\"]: break\n",
    "        try:\n",
    "            img = Image.open(result[\"image_path\"])\n",
    "        except FileNotFoundError: continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 12))\n",
    "        ax.imshow(img); ax.axis(\"off\")\n",
    "\n",
    "        title = f\"Result {i+1}: {'CORRECT' if result['is_correct'] else 'INCORRECT'}\"\n",
    "        fig.suptitle(title, fontsize=18, color='green' if result['is_correct'] else 'red', y=0.95)\n",
    "\n",
    "        gt_attrs_str = (f\"Ground Truth:\\n\"\n",
    "                        f\"  - Name: {result['gt_attrs'].get('name', 'N/A')}\\n\"\n",
    "                        f\"  - Age: {result['gt_attrs'].get('age_group', 'N/A')}\\n\"\n",
    "                        f\"  - Expression: {result['gt_attrs'].get('expression', 'N/A')}\")\n",
    "\n",
    "        pred_attrs_str = (f\"Prediction:\\n\"\n",
    "                          f\"  - Name: {result['pred_attrs'].get('name', 'N/A')}\\n\"\n",
    "                          f\"  - Age: {result['pred_attrs'].get('age_group', 'N/A')}\\n\"\n",
    "                          f\"  - Expression: {result['pred_attrs'].get('expression', 'N/A')}\")\n",
    "\n",
    "        plt.figtext(0.1, 0.02, gt_attrs_str, ha=\"left\", fontsize=12, wrap=True, va=\"bottom\")\n",
    "        plt.figtext(0.9, 0.02, pred_attrs_str, ha=\"right\", fontsize=12, wrap=True, va=\"bottom\",\n",
    "                    color='green' if result['is_correct'] else 'red')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.1, 1, 0.9])\n",
    "\n",
    "        save_name = f\"result_{i+1}_{'correct' if result['is_correct'] else 'incorrect'}.png\"\n",
    "        plt.savefig(os.path.join(CONFIG[\"plot_save_dir\"], save_name), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"--- Plotting complete ---\")\n",
    "\n",
    "# ==============================\n",
    "#      MAIN EXECUTION BLOCK\n",
    "# ==============================\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Using device: {CONFIG['device']}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch Version: {torch.__version__}, CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "        CONFIG[\"model_name\"], pretrained=CONFIG[\"pretrained\"], device=CONFIG[\"device\"]\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(CONFIG[\"model_name\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_prompts = CONFIG[\"identity_prompts\"] + CONFIG[\"gender_prompts\"] + CONFIG[\"age_prompts\"] + CONFIG[\"expression_prompts\"]\n",
    "        all_text_tokens = tokenizer(all_prompts).to(CONFIG[\"device\"])\n",
    "        all_text_features = model.encode_text(all_text_tokens)\n",
    "        all_text_features = all_text_features / all_text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    train_df = preprocess_and_cache_csv(CONFIG[\"csv_train\"])\n",
    "    val_df = preprocess_and_cache_csv(CONFIG[\"csv_val\"])\n",
    "\n",
    "    if train_df is not None and val_df is not None and not train_df.empty and not val_df.empty:\n",
    "        train_dataset = MultiAttributeDataset(train_df, preprocess)\n",
    "        val_dataset = MultiAttributeDataset(val_df, preprocess)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "        training_successful = train_and_validate(model, train_loader, val_loader, all_text_features)\n",
    "\n",
    "        if training_successful:\n",
    "            test_and_plot(model, all_text_features, preprocess)\n",
    "        else:\n",
    "            print(\"\\nSkipping testing phase: No model was saved during training.\")\n",
    "    else:\n",
    "        print(\"\\nSkipping training: Training/validation datasets are empty or could not be loaded.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch Version: 2.8.0.dev20250507+cu128, CUDA Version: 12.8\n",
      "Loading preprocessed data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/train.multi_attribute_cached.csv\n",
      "Loading preprocessed data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/valid.multi_attribute_cached.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  5.88it/s]\n",
      "Epoch 1/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1: Train Loss = 5.1747, Val Loss = 4.3018\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.00it/s]\n",
      "Epoch 2/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2: Train Loss = 3.5331, Val Loss = 3.7214\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.08it/s]\n",
      "Epoch 3/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3: Train Loss = 2.6807, Val Loss = 3.4568\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.08it/s]\n",
      "Epoch 4/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4: Train Loss = 2.0048, Val Loss = 3.1154\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.13it/s]\n",
      "Epoch 5/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5: Train Loss = 1.4758, Val Loss = 3.0992\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.16it/s]\n",
      "Epoch 6/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6: Train Loss = 1.0434, Val Loss = 3.0526\n",
      "ðŸŽ‰ Saved best model to finetuned_multi_attribute_final_consistent.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.12it/s]\n",
      "Epoch 7/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7: Train Loss = 0.7179, Val Loss = 3.1969\n",
      "âš ï¸ No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.17it/s]\n",
      "Epoch 8/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8: Train Loss = 0.4566, Val Loss = 3.1324\n",
      "âš ï¸ No improvement. Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.11it/s]\n",
      "Epoch 9/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9: Train Loss = 0.2906, Val Loss = 3.3067\n",
      "âš ï¸ No improvement. Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.13it/s]\n",
      "Epoch 10/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10: Train Loss = 0.1748, Val Loss = 3.3325\n",
      "âš ï¸ No improvement. Patience: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.11it/s]\n",
      "Epoch 11/100 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 11: Train Loss = 0.0985, Val Loss = 3.4741\n",
      "âš ï¸ No improvement. Patience: 5/5\n",
      "ðŸ›‘ Early stopping triggered.\n",
      "\n",
      "--- Starting Final Testing and Plotting Phase ---\n",
      "Best model loaded.\n",
      "Loading preprocessed data from cache: C:/Users/yehte/Downloads/Ye Htet/Projects/TikTok/Annotation/fine-tune/test.multi_attribute_cached.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "ðŸ“Š Attribute Accuracy: 43.00% (Correct if Name, Age, and Expression all match)\n",
      "\n",
      "--- Plotting up to 100 results ---\n",
      "--- Plotting complete ---\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fecd1aa066d3f85f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
